{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaOWkXiHoN4H"
      },
      "source": [
        "# **Master** **Of** **Data** **Science** **NoteBook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoQ303Bloa9n"
      },
      "source": [
        "## Analyzing the dataset for my research on : **Preserving** **and reviving the Oshiwambo language through hybrid SVM-Deep Learning Models**, using Python Jupyter notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df7eEzW2Z7bY"
      },
      "source": [
        "# ***DATA CLEANING***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzR2gP_saZGH"
      },
      "source": [
        "# TOKENIZATION AND CLEANING WITH NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDCCJFaLvgsX",
        "outputId": "d23dd8c8-4931-429b-8268-bba37e3c5115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in DataFrame after stripping spaces:\n",
            "Index(['Oshiwambo', 'Aa-ndonga', 'Aa-kwambi', 'Aa-mbalanhu', 'Aa-kwaluudhi',\n",
            "       'Aa-kwanyama', 'Aa-ngandjera', 'Aa-mbandja'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "\n",
        "# Load your CSV file\n",
        "file_path = '/content/sample_data/Thesis_Dataset - Sheet1.CSV'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Strip any extra spaces from the column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Print column names to check if they match after stripping\n",
        "print(\"Columns in DataFrame after stripping spaces:\")\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Download the 'punkt' tokenizer if not already downloaded\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "CIadWtrMD5sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# List of columns to be processed (after removing spaces from column names)\n",
        "columns_to_process = [\n",
        "    'Oshiwambo', 'Aa-ndonga', 'Aa-kwambi',\n",
        "    'Aa-mbalanhu', 'Aa-kwaluudhi',\n",
        "    'Aa-kwanyama', 'Aa-ngandjera', 'Aa-mbandja'\n",
        "]\n",
        "# Function to tokenize and remove punctuation (no stemming)\n",
        "def clean_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove punctuation and non-alphabetic tokens\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the cleaning function (tokenize and remove punctuation) to each specified column\n",
        "for column in columns_to_process:\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].astype(str).apply(clean_text)\n",
        "    else:\n",
        "        print(f\"Column '{column}' not found in DataFrame.\")\n",
        "\n",
        "# Display the first few rows of the cleaned DataFrame (without stemming)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "3EB1EOjF3Dov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ba5622-d30c-42e2-9cbf-e139277bee3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Oshiwambo Aa-ndonga  Aa-kwambi Aa-mbalanhu Aa-kwaluudhi Aa-kwanyama  \\\n",
            "0       Ame     Ngame      Ngaye        Aame         Amee         Ame   \n",
            "1       Ove     Ngoye      Ngwee         Oye          Oye         Ove   \n",
            "2                  Ye         Ye          Ye           Ye          Ye   \n",
            "3      Fyee       Tse         Se          Se           Se         Fye   \n",
            "4    Amushe        Ne  Ne amushe         Nye        Amuhe         Nye   \n",
            "\n",
            "  Aa-ngandjera Aa-mbandja  \n",
            "0        Ngaye        Ame  \n",
            "1        Ngwee        ove  \n",
            "2           Ye             \n",
            "3          Tse             \n",
            "4           Ne             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Porter Stemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# Function to stem words in the \"Oshiwambo\" column\n",
        "def stem_words(text):\n",
        "    # Assume the text is already tokenized, just apply stemming\n",
        "    stemmed = [porter.stem(word) for word in text.split()]  # Apply stemming to tokenized words\n",
        "    return ' '.join(stemmed)\n",
        "\n",
        "# Apply stemming to the \"Oshiwambo\" column and replace the original column with stemmed text\n",
        "df['Oshiwambo'] = df['Oshiwambo'].astype(str).apply(stem_words)\n",
        "\n",
        "# Display the first few rows of the DataFrame with the replaced \"Oshiwambo\" column\n",
        "print(df.head())\n",
        "\n",
        "# Example: Print the first 100 stemmed words from the 'Oshiwambo' column\n",
        "osh_stemmed_flat = [word for sublist in df['Oshiwambo'].str.split() for word in sublist]\n",
        "print(osh_stemmed_flat[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNu_9E3jNso7",
        "outputId": "386536fa-e557-44aa-b216-d4bb88619db6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Oshiwambo Aa-ndonga  Aa-kwambi Aa-mbalanhu Aa-kwaluudhi Aa-kwanyama  \\\n",
            "0       ame     Ngame      Ngaye        Aame         Amee         Ame   \n",
            "1       ove     Ngoye      Ngwee         Oye          Oye         Ove   \n",
            "2                  Ye         Ye          Ye           Ye          Ye   \n",
            "3      fyee       Tse         Se          Se           Se         Fye   \n",
            "4     amush        Ne  Ne amushe         Nye        Amuhe         Nye   \n",
            "\n",
            "  Aa-ngandjera Aa-mbandja  \n",
            "0        Ngaye        Ame  \n",
            "1        Ngwee        ove  \n",
            "2           Ye             \n",
            "3          Tse             \n",
            "4           Ne             \n",
            "['ame', 'ove', 'fyee', 'amush', 'voo', 'meme', 'tate', 'omwaina', 'kadona', 'omwaina', 'mati', 'umweinafana', 'onhu', 'adala', 'kumweina', 'wamem', 'or', 'tate', 'woy', 'tatekulu', 'okatekulu', 'kokamati', 'okatekulu', 'kokakadona', 'tate', 'mweno', 'oofelend', 'mee', 'mweno', 'nawa', 'ongula', 'okuhala', 'komatango', 'oku', 'tokelwa', 'uufiku', 'walelepo', 'wauhalapo', 'watokelwapo', 'ngeipi', 'endapo', 'nawa', 'kalapo', 'nawa', 'ka', 'nangalepo', 'nawa', 'nangalapo', 'nawa', 'heeno', 'ahaw', 'eewa', 'onda', 'fya', 'ondjala', 'onda', 'fya', 'enota', 'onda', 'kuta', 'onda', 'pwapo', 'onda', 'loloka', 'nda', 'hala', 'ku', 'nangala', 'openi', 'pena', 'omeva', 'iha', 'ndili', 'ombelela', 'nghuuditeko', 'iikulya', 'oiwa', 'tangi', 'unen', 'nghi', 'shishi', 'omeva', 'oshi', 'yaha', 'oku', 'kotha', 'lala', 'okulya', 'okwiiyoga', 'othewa', 'yokwiiyoga', 'elehita', 'okakopi', 'ombiila', 'kwathela', 'oshipatululo', 'osho', 'oshithima', 'onyama', 'omboga']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CdPw2qMFvwzW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **One-Hot Encoding**"
      ],
      "metadata": {
        "id": "2bH3xPu7bF18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Z4OzqeNof8H3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# List of columns to be one-hot encoded\n",
        "columns_to_encode = [\"Oshiwambo\", \"Aa-ndonga\", \"Aa-kwambi\", \"Aa-mbalanhu\", \"Aa-kwaluudhi\", \"Aa-kwanyama\", \"Aa-ngandjera\", \"Aa-mbandja\"]\n",
        "\n",
        "# Initialize the OneHotEncoder with the updated parameter\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Fit and transform the selected columns into one-hot encoded format\n",
        "one_hot_encoded = encoder.fit_transform(df[columns_to_encode])\n",
        "\n",
        "# Print the shape of the one-hot encoded data\n",
        "print(f\"One-hot encoded shape: {one_hot_encoded.shape}\")\n",
        "\n",
        "# Example: Display a few rows of one-hot encoded data\n",
        "print(one_hot_encoded[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90lnbccZmcOD",
        "outputId": "2589f596-65b5-451a-b0ac-84d8febcc107"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded shape: (570, 3796)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "d1GLrJFa5fhn"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM or CNN for Feature Extraction**"
      ],
      "metadata": {
        "id": "QVFQ9Yi9bKGc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hKTxnVf8Eoz"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "JKQX_AzPpv-q"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Input\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the Input layer explicitly\n",
        "model.add(Input(shape=(X.shape[1], 1)))  # Input shape: (time steps, features)\n",
        "\n",
        "# Add an LSTM layer\n",
        "model.add(LSTM(units=64, return_sequences=False))\n",
        "\n",
        "# Add a Dense layer for feature extraction or classification\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Optionally, add a Dropout layer for regularization\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer for binary classification (adjust for multi-class as needed)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Example: Fit the model (assuming y is the label for classification)\n",
        "# Replace 'y' with your actual labels\n",
        "# model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "1ebtAFH1qA-y",
        "outputId": "1a718c4e-6a34-4792-9b83-3dc84712cb88"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,009\u001b[0m (74.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,009</span> (74.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,009\u001b[0m (74.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,009</span> (74.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCKPbnyi8aWv"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "\n",
        "# Reshape one_hot_encoded data to 3D (samples, time steps, features)\n",
        "X = one_hot_encoded.reshape((one_hot_encoded.shape[0], one_hot_encoded.shape[1], 1))\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a 1D convolutional layer\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)))\n",
        "\n",
        "# Global Max Pooling layer\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Add a Dense layer for feature extraction or classification\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Optionally, add a Dropout layer for regularization (optional)\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Example: Fit the model (assuming y is the label for classification)\n",
        "# Replace 'y' with your actual labels\n",
        "# model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "VRkyyQPKnlN_",
        "outputId": "c5dd3741-c87f-43c4-cf40-b5f644bd85a6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3792\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m384\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3792</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,497\u001b[0m (9.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,497</span> (9.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,497\u001b[0m (9.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,497</span> (9.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM for Classification**"
      ],
      "metadata": {
        "id": "ci5k7nCEbfxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'features' contains the extracted features from LSTM/CNN and 'labels' are the true labels\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(one_hot_encoded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the SVM classifier\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vBu7uuGdbm4B",
        "outputId": "901fc438-ac5b-48f2-984e-1c65cf35be5c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-28638a4b1f3a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming 'features' contains the extracted features from LSTM/CNN and 'labels' are the true labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split the dataset into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Initialize the SVM classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBz6_o28C7T7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you've defined your LSTM model and trained it first\n",
        "# For example:\n",
        "# model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# After training, create the feature extractor\n",
        "feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)  # Use -2 for the last Dense layer before output\n",
        "\n",
        "# Use the LSTM model to predict/extract features from the one-hot encoded data\n",
        "# Reshape X as before to 3D (samples, time steps, features)\n",
        "X = one_hot_encoded.reshape((one_hot_encoded.shape[0], one_hot_encoded.shape[1], 1))\n",
        "\n",
        "# Extract features from the LSTM model\n",
        "features = feature_extractor.predict(X)\n",
        "\n",
        "# Now 'features' can be used for SVM input\n",
        "# Assuming 'labels' contains the true labels for the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the SVM classifier\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "BllFedpabwT5",
        "outputId": "9e1b6442-c7ab-4201-b136-c36697fdd7bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The layer sequential_5 has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-18591652360b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# After training, create the feature extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use -2 for the last Dense layer before output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Use the LSTM model to predict/extract features from the one-hot encoded data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The layer sequential_5 has never been called and thus has no defined input."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Fusion: Combining SVM and Deep Learning Models**"
      ],
      "metadata": {
        "id": "b7feRl6IbxAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Option 1: Use SVM on Deep Learning Features\n",
        "\n",
        "# Get the features from the LSTM or CNN layer (e.g., intermediate layers)\n",
        "intermediate_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "lstm_cnn_features = intermediate_model.predict(one_hot_encoded)\n",
        "\n",
        "# Use these features as input to the SVM classifier\n",
        "svm_classifier.fit(lstm_cnn_features, labels)\n",
        "\n",
        "# Evaluate SVM performance\n",
        "y_pred_svm = svm_classifier.predict(lstm_cnn_features)\n",
        "print(f\"Fused Model Accuracy: {accuracy_score(labels, y_pred_svm)}\")\n"
      ],
      "metadata": {
        "id": "cbyyum--b3jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Option 2: Ensemble Method (Combine Probabilities)\n",
        "# Example: Combining probabilities of SVM and Deep Learning model for final prediction\n",
        "lstm_cnn_prob = model.predict(one_hot_encoded)\n",
        "svm_prob = svm_classifier.decision_function(one_hot_encoded)\n",
        "\n",
        "# Combine predictions (example: average the probabilities)\n",
        "final_prob = (lstm_cnn_prob + svm_prob) / 2\n",
        "final_pred = [1 if prob > 0.5 else 0 for prob in final_prob]\n",
        "\n",
        "# Evaluate combined model performance\n",
        "print(f\"Ensemble Model Accuracy: {accuracy_score(labels, final_pred)}\")\n"
      ],
      "metadata": {
        "id": "DJlWpWjnb7EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tb_nRPvGb60R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QLxjhIOQg7Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Architecture Flow Chart for Hybrid Model:\n",
        "\n",
        "1. **Data Input**:\n",
        "   - Input: Raw text data from multiple columns (e.g., `Oshiwambo`, `Aa-ndonga`, etc.)\n",
        "   \n",
        "2. **Data Cleaning**:\n",
        "   - Tokenization\n",
        "   - Punctuation Removal\n",
        "   - Stemming (applied only to the `Oshiwambo` column)\n",
        "   - Output: Cleaned tokenized text data\n",
        "   \n",
        "3. **One-Hot Encoding**:\n",
        "   - Convert cleaned text into numerical format (One-Hot Encoding)\n",
        "   - Output: Encoded feature matrix\n",
        "\n",
        "4. **Feature Extraction**:\n",
        "   - **Path 1: LSTM Model**:\n",
        "     - LSTM is used to extract sequential patterns from the encoded data.\n",
        "     - Output: LSTM feature vector\n",
        "   - **Path 2: CNN Model**:\n",
        "     - CNN is used to capture local features from the encoded text data.\n",
        "     - Output: CNN feature vector\n",
        "\n",
        "5. **SVM Classification**:\n",
        "   - SVM is trained using features from LSTM/CNN to categorize language patterns.\n",
        "   - Output: Classified language patterns (e.g., dialects)\n",
        "\n",
        "6. **Model Fusion**:\n",
        "   - Combine the outputs of the SVM and LSTM/CNN models.\n",
        "   - Output: Final prediction based on the fusion of both models.\n",
        "\n",
        "### Labels:\n",
        "- Data Cleaning → Preprocessing → Feature Extraction → Classification → Model Fusion → Final Output\n"
      ],
      "metadata": {
        "id": "YKud1AFTg72D"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}